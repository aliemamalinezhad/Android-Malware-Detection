import tensorflow as tf



from keras.preprocessing import sequence
import time
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.layers import Embedding
from keras.layers import LSTM
from sklearn.metrics import confusion_matrix, precision_score, recall_score, cohen_kappa_score
import keras_metrics
from keras.layers import Conv1D, MaxPooling1D
from keras.datasets import imdb
from sklearn import preprocessing, svm
import pandas as pd
from keras.optimizers import SGD, Adam, Nadam, Adagrad
from sklearn.model_selection import StratifiedKFold
from keras.layers import BatchNormalization

from keras.layers import Dense, Dropout, LSTM, Embedding, Activation
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.optimizers import SGD, Adam, Nadam
import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score
from keras.utils.vis_utils import plot_model
from keras.layers.normalization import BatchNormalization
import keras
import keras_metrics
from keras import backend as K
import matplotlib.pyplot as plt

input_file = 'dataset.csv'

df = pd.read_csv(input_file)

X = np.array(df.drop(['label'], 1))
df.dropna(inplace=True)
y = np.array(df['label'])
X_train, X_test, y_train, y_test =train_test_split (X, y, test_size=0.2)



# def load_data(test_split = 0.2):
#     print ('Loading data...')
#     df = pd.read_csv(input_file)
#     df['sequence'] = df['sequence'].apply(lambda x: [int(e) for e in x.split()])
#     df = df.reindex(np.random.permutation(df.index))

#     train_size = int(len(df) * (1 - test_split))

#     X_train = df['sequence'].values[:train_size]
#     y_train = np.array(df['target'].values[:train_size])
#     X_test = np.array(df['sequence'].values[train_size:])
#     y_test = np.array(df['target'].values[train_size:])

#     return pad_sequences(X_train), y_train, pad_sequences(X_test), y_test


def create_model(input_length):
    print ('Creating model...')
    model = Sequential()

    model.add(Dense(64, input_dim=9, init='uniform'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(Dropout(0.5))
    model.add(Dense(64, init='uniform'))
    model.add(Activation('tanh'))
    model.add(BatchNormalization())
    model.add(Dropout(0.5))
    model.add(Dense(1, init='uniform'))
    model.add(Activation('softmax'))

    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
    adam = Adam(lr=0.05)


    print ('Compiling...')
    model.compile(loss='categorical_crossentropy',
                  optimizer=Adam(lr=0.12, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),
                  metrics=['accuracy',keras_metrics.precision(), keras_metrics.recall(),keras_metrics.false_positive(), keras_metrics.false_negative()])

                  #keras_metrics.false_positive(), keras_metrics.false_negative()
    return model





# X_train, y_train, X_test, y_test = load_data()

print(X_train.shape)

model = create_model(len(X_train[0]))

print ('Fitting model...')
history = model.fit(X_train, y_train, batch_size=10, nb_epoch=1000, validation_split = 0.1, verbose = 1)

score, acc, prec, rec, false_positive, false_negative = model.evaluate(X_test, y_test, batch_size=50)
# print('Test score:', score)
# print("----------------------------------------------------------")
print("----------------------------------------------------------")
print("----------------------------------------------------------")
print('Test accuracy:', acc ,prec,rec)
print("----------------------------------------------------------")
print("----------------------------------------------------------")

# print(false_negative)





model.summary()

# y_pred = model.predict(X_test)
# y_pred = (y_pred > 0.5)
# cm = confusion_matrix(y_test, y_pred)
# print(cm)

# plt.matshow(cm,cmap='RdBu')
# plt.title('Confusion matrix')
# plt.colorbar()
# plt.ylabel('True label')
# plt.xlabel('Predicted label')
# plt.show()