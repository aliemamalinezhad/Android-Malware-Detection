import tensorflow as tf

from keras.layers import Dense, Dropout, LSTM, Embedding, Activation
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.optimizers import SGD, Adam, Nadam
import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score
from keras.utils.vis_utils import plot_model
from keras.layers.normalization import BatchNormalization
import keras
import keras_metrics
from functools import reduce
from keras import backend as K
import time
from sklearn.model_selection import StratifiedKFold

input_file = 'input.csv'

def train_evaluate(model, x_train, y_train, x_test, y_test):
    model.fit(x_train, y_train,batch_size=32, nb_epoch=1000)
    return model.evaluate(x_test, y_test)


def load_data(test_split = 0.2):
    print ('Loading data...')
    df = pd.read_csv(input_file)
    df['sequence'] = df['sequence'].apply(lambda x: [int(e) for e in x.split()])
    df = df.reindex(np.random.permutation(df.index))

    train_size = int(len(df) * (1 - test_split))

    X_train = df['sequence'].values[:train_size]
    y_train = np.array(df['target'].values[:train_size])
    X_test = np.array(df['sequence'].values[train_size:])
    y_test = np.array(df['target'].values[train_size:])

    return pad_sequences(X_train), y_train, pad_sequences(X_test), y_test


def create_model():
    print ('Creating model...')
    model = Sequential()


    model.add(Dense(256, input_dim=132, init='uniform'))
    model.add(BatchNormalization())
    model.add(Activation('tanh'))
    model.add(Dropout(0.3))
    model.add(Dense(256, init='uniform'))
    model.add(Activation('tanh'))
    model.add(BatchNormalization())
    model.add(Dropout(0.5))
    model.add(Dense(1, init='uniform'))
    model.add(Activation('sigmoid'))

    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)
    adam = Adam(lr=0.02)


    print ('Compiling...')
    model.compile(loss='binary_crossentropy',
                  optimizer=Adam(lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),
                  metrics=['accuracy',keras_metrics.precision(), keras_metrics.recall(),keras_metrics.false_positive(), keras_metrics.false_negative()])

                  #keras_metrics.false_positive(), keras_metrics.false_negative()
    return model
X_train, y_train, X_test, y_test = load_data()
# X, Y = load_model()
df = pd.read_csv(input_file)
X = df['sequence']
Y = df['target']
kFold = StratifiedKFold(n_splits=4)
scores = np.zeros(10)
idx = 0
# ///////////
start_time = time.time()
# //////////
model = create_model()

for train, test in kFold.split(X, Y):
    scores = train_evaluate(model, X_train, y_train, X_test, y_test)
    print(">>>>>>>>>>>>>>>>>>>>>>," ,scores)

print("---------------%s seconds----------" % (time.time() - start_time))



    # idx += 1

# print (reduce(lambda x, y: x + y, scores)/len(scores))


# X_train, y_train, X_test, y_test = load_data()
#
# print(X_train.shape)
# start_time = time.time()
#
# model = create_model(len(X_train[0]))
#
# print ('Fitting model...')
# history = model.fit(X_train, y_train, batch_size=10, nb_epoch=1000, validation_split = 0.1, verbose = 1)
#
# print("---------------%s seconds----------" % (time.time() - start_time))
#
#
# score, acc, prec, rec, false_positive, false_negative = model.evaluate(X_test, y_test, batch_size=50)
# # print('Test score:', score)
# # print("----------------------------------------------------------")
# print("----------------------------------------------------------")
# print("----------------------------------------------------------")
# print('Test accuracy:', acc )
# print("----------------------------------------------------------")
# print("----------------------------------------------------------")
#
# # print(false_negative)
#




model.summary()
